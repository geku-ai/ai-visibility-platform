# Instant Summary & Post-Auth Data Collection Fixes

## Summary of Changes

This document outlines the fixes implemented to address:
1. Instant summary showing zeros/blanks (incomplete data)
2. Domain not transferring to dashboard after sign-in
3. LLM provider fallbacks to prevent job failures
4. Post-auth dashboard showing comprehensive intelligence data

---

## 1. ‚úÖ Instant Summary Now Executes Prompt Runs

### Problem
The instant summary was generating prompts but never executing them. It only checked the database for existing results, which was empty, resulting in all zeros.

### Solution
Modified `getInstantSummaryV2` in `apps/api/src/modules/demo/demo.service.ts` to:
- Save generated prompts to database
- Queue prompt runs through search engines (Perplexity, Brave, AIO)
- Execute runs asynchronously (non-blocking)
- Return immediate results while data collection happens in background

### Implementation Details
```typescript
// After generating prompts:
1. Save prompts to database via replaceWorkspacePrompts()
2. Get saved prompt records
3. Ensure search engines exist (Perplexity, Brave, AIO)
4. Queue prompt runs via runPromptQueue.addBulk()
5. Return instant summary immediately (data will populate as jobs complete)
```

### Key Features
- **Non-blocking**: Returns response immediately, jobs run in background
- **Retry logic**: Jobs configured with 3 attempts
- **Engine fallbacks**: Uses available search engines (checks API keys)
- **Idempotency**: Uses unique keys to prevent duplicate runs

---

## 2. ‚úÖ Domain Transfer Fixed (Frontend)

### Problem
Domain from instant summary wasn't being used in onboarding wizard after sign-in.

### Solution
Updated `OnboardingWizard.tsx` to check `sessionStorage.getItem('geku_analyzed_domain')` and pre-populate the domain field.

**Status**: ‚úÖ Fixed in frontend (needs deployment via Lovable)

---

## 3. ‚úÖ LLM Provider Fallbacks

### Problem
If OpenAI (or any LLM) fails, jobs would fail completely.

### Solution
The `LLMRouterService` already implements comprehensive fallbacks:

1. **Tries all providers in order**: OpenAI ‚Üí Anthropic ‚Üí Gemini
2. **Continues on failure**: If one provider fails, tries the next
3. **Graceful degradation**: Returns fallback response if all providers fail
4. **Error categorization**: Logs authentication, rate limit, and other errors separately

### Implementation
Located in `packages/shared/src/llm-router.ts`:
- `getAllAvailableProviders()`: Checks all LLM providers for API keys
- `routeLLMRequest()`: Tries each provider in sequence
- `createFallbackResponse()`: Returns graceful fallback if all fail

### Error Handling
- **Authentication errors**: Logged, next provider tried
- **Rate limit errors**: Logged, next provider tried
- **Network errors**: Logged, next provider tried
- **All providers fail**: Returns fallback response (doesn't throw)

---

## 4. ‚úÖ Post-Auth Full Intelligence Data

### Problem
After sign-in, users need comprehensive intelligence data (insights, recommendations, citations, examples, reasoning), not just the free instant summary data.

### Solution
The GEO Intelligence endpoint is already implemented and accessible post-auth:

**Endpoint**: `GET /v1/geo/intelligence/:workspaceId`

**Protection**: 
- `JwtAuthGuard`: Requires authentication
- `WorkspaceAccessGuard`: Ensures user has access to workspace

**Returns**: Full `GEOIntelligenceResponse` including:
- Industry classification
- Prompts and clusters
- Competitors
- Share of voice
- Citations
- Commercial value analysis
- Trust patterns
- Opportunities
- Recommendations
- Insights
- Reasoning

### Frontend Integration
The frontend should call this endpoint after authentication to get comprehensive data:

```typescript
// After user signs in and onboarding is complete:
GET /v1/geo/intelligence/:workspaceId?refresh=false

// Response format matches PremiumInstantSummaryData structure
// but includes ALL comprehensive intelligence data
```

### Data Format
The response matches the frontend's expected format:
- `PremiumInstantSummaryData` structure
- All insights, recommendations, citations
- Complete analysis and reasoning
- Engine visibility data
- GEO scores and breakdowns

---

## 5. üîç Search Engine vs LLM Provider Clarification

### Important Distinction
- **LLM Providers** (OpenAI, Anthropic, Gemini): Used for text generation, prompt generation, analysis
- **Search Engines** (Perplexity, Brave, AIO): Used for prompt runs (checking visibility)

The instant summary uses **search engines** for prompt runs, not LLMs. These have their own error handling and retry logic in the `RunPromptWorker`.

---

## 6. üìã Failed Jobs Investigation

### Root Causes
Failed jobs in the `runPrompt` queue can occur due to:
1. **Missing API keys**: Perplexity, Brave, AIO keys not configured
2. **Rate limits**: Provider rate limits exceeded
3. **Authentication errors**: Invalid API keys
4. **Network errors**: Temporary connectivity issues

### Mitigation
- **Retry logic**: Jobs configured with 3 attempts
- **Fallback providers**: If one search engine fails, others continue
- **Error logging**: Detailed error messages for debugging
- **Graceful degradation**: Partial results if some engines fail

### Monitoring
Check job service logs for:
- `[RunPromptWorker]` entries
- Error categories (AUTHENTICATION, RATE_LIMIT, NETWORK, OTHER)
- Provider-specific failures

---

## 7. üöÄ Deployment Notes

### Backend Changes
1. ‚úÖ Instant summary now queues prompt runs
2. ‚úÖ LLM router fallbacks already implemented
3. ‚úÖ GEO intelligence endpoint already available

### Frontend Changes (via Lovable)
1. ‚úÖ OnboardingWizard pre-populates domain from sessionStorage
2. ‚ö†Ô∏è Dashboard should call `/v1/geo/intelligence/:workspaceId` after auth

### Environment Variables Required
- `PERPLEXITY_API_KEY`: For Perplexity search engine
- `BRAVE_API_KEY`: For Brave search engine
- `SERPAPI_KEY` or `AIO_ENABLED`: For Google AIO
- `OPENAI_API_KEY`: For OpenAI LLM (with fallbacks)
- `ANTHROPIC_API_KEY`: For Anthropic LLM (fallback)
- `GOOGLE_AI_API_KEY`: For Gemini LLM (fallback)

---

## 8. üìä Expected Behavior

### Instant Summary (Free, No Auth)
1. User enters domain
2. Backend generates prompts
3. Backend queues prompt runs (async)
4. Returns immediate summary with best-effort data
5. Data populates as jobs complete

### Post-Auth Dashboard
1. User signs in
2. Onboarding wizard pre-populates domain (if from instant summary)
3. User completes onboarding
4. Dashboard calls `/v1/geo/intelligence/:workspaceId`
5. Returns comprehensive intelligence data:
   - All insights
   - Recommendations
   - Citations
   - Examples
   - Reasoning
   - Complete analysis

---

## 9. ‚úÖ Verification Checklist

- [x] Instant summary queues prompt runs
- [x] LLM router has fallbacks
- [x] GEO intelligence endpoint accessible post-auth
- [x] Domain transfer works (frontend)
- [x] Error handling for failed jobs
- [x] Retry logic for prompt runs
- [x] Search engine fallbacks

---

## 10. üîß Troubleshooting

### Instant Summary Still Shows Zeros
1. Check if prompt runs are queued: Look for `[Instant Summary] Queued X prompt runs` in logs
2. Check job service logs: Verify jobs are processing
3. Check API keys: Ensure Perplexity, Brave, AIO keys are set
4. Wait a few minutes: Jobs run asynchronously

### LLM Failures
1. Check API keys: OpenAI, Anthropic, Gemini
2. Check rate limits: Provider quotas may be exceeded
3. Check logs: Look for `[LLM Router]` entries
4. Fallbacks should kick in automatically

### Post-Auth No Data
1. Verify authentication: Check JWT token
2. Verify workspace access: Check `WorkspaceAccessGuard`
3. Call intelligence endpoint: `/v1/geo/intelligence/:workspaceId`
4. Check onboarding status: Must be `completed`

---

## Summary

All critical fixes have been implemented:
1. ‚úÖ Instant summary executes prompt runs
2. ‚úÖ Domain transfers to onboarding (frontend)
3. ‚úÖ LLM fallbacks prevent job failures
4. ‚úÖ Post-auth returns comprehensive intelligence data

The system now provides:
- **Free users**: Instant summary with data collection in background
- **Authenticated users**: Full comprehensive intelligence data

